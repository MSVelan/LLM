# LLM

## Query Comparison and Response System

This project demonstrates a sophisticated system that leverages a custom search implementation (minsearch) and the Gemini API to provide accurate, context-based responses to user queries.

Features:

* Custom Search Algorithm: Utilizes minsearch to efficiently search through questions in a document.json file.
** To learn more about the implementation of minsearch and elastic search, checkout this repository: [Search-Implementation](https://github.com/MSVelan/Search-Engine-Implementation) 

* Contextual Responses: Employs the Gemini API to generate precise responses based on the context provided by search results.
* Prompt Engineering: Implements RAG with prompt engineering to enhance response accuracy.
* Environment Configuration: Uses a .env file for secure environment variable management.

### Project Structure

minsearch.py: Contains the summary and implementation of the custom search algorithm.

rag-intro.ipynb: Implements RAG using the GEMINI generative model and prompt engineering.

.env: Stores environment variables, including GOOGLE_API_KEY.

### Setup

1. Clone the Repository:

   bash

       git clone https://github.com/your-username/your-repository.git
       cd your-repository

2. Install Dependencies:

   bash

       pipenv shell
       pipenv install 

3. Set Environment Variables:
   Create a .env file in the root directory and add your GOOGLE_API_KEY:

   env

       GOOGLE_API_KEY=your_google_api_key

4. Run the Project:
   Open and run the rag-intro.ipynb notebook to see the RAG implementation with GEMINI.

### Usage

Query Input: Enter your query in the rag-intro.ipynb notebook.
Response Output: Receive contextually accurate responses according to the documents.json generated by the GEMINI model based on the matched queries from minsearch.
